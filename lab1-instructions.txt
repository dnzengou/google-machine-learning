Renting a VM to Process Earthquake Data
2 hours
Free
Rate Lab
Overview
Using Google Cloud to set up a virtual machine to process earthquake data frees you from IT minutia to focus on your scientific goals. You can ingest and process data, then present the results in various formats. In this lab, you will ingest real-time earthquake data published by the United States Geological Survey (USGS) and create maps that look like the following:

usgs_map.png

In this lab, you will spin up a virtual machine, access it remotely, and then manually create a pipeline to retrieve, process and publish the data.

What you will learn
In this lab, you will learn how to do the following:

Create a Compute Engine instance with specific security permissions.

SSH into the instance.

Install the software package Git (for source code version control).

Ingest data into the Compute Engine instance.

Transform data on the Compute Engine instance.

Store the transformed data on Cloud Storage.

Publish Cloud Storage data to the web.

Setup
For each lab, you get a new Google Cloud project and set of resources for a fixed time at no cost.

Make sure you signed into Qwiklabs using an incognito window.

Note the lab's access time (for example, img/time.png and make sure you can finish in that time block.

There is no pause feature. You can restart if needed, but you have to start at the beginning.

When ready, click img/start_lab.png.

Note your lab credentials. You will use them to sign in to the Google Cloud Console. img/open_google_console.png

Click Open Google Console.

Click Use another account and copy/paste credentials for this lab into the prompts.

If you use other credentials, you'll get errors or incur charges.

Accept the terms and skip the recovery resource page.
Do not click End Lab unless you are finished with the lab or want to restart it. This clears your work and removes the project.

Task 1. Create Compute Engine instance with the necessary API access
To create a Compute Engine instance, click on Navigation menu > Compute Engine > VM instances:

vm_instances.png

Click Create and wait for the Create an instance form to load:

create_vm.png

Use default Region and Zone for creating the instance:

default_region_and_zone.png

Use default Boot disk image (Debian). Do not change the boot disk image.

boot_disk.png

Change Identity and API access > Access scopes for the Compute Engine default service account to Allow full access to all Cloud APIs, then click Create.

api_access.png

You'll see a green circle with a check when the instance is created.

Click Check my progress to verify the objective.
Create Compute Engine instance with the necessary API access

SSH into the instance
You can remotely access your Compute Engine instance using Secure Shell (SSH):

Click the SSH button next to your newly created VM:

ssh_button.png

The VM instance details displays.

Note: Make sure your browser is not blocking pop-ups.
SSH keys are automatically transferred; no extra software is needed to ssh directly from the browser.

To find some information about the Compute Engine instance, type the following into the command-line and press Enter:

cat /proc/cpuinfo
You should see the similar output (Don't Copy):

processor       : 0
vendor_id       : GenuineIntel
cpu family      : 6
model           : 63
model name      : Intel(R) Xeon(R) CPU @ 2.30GHz
....              
Task 2. Install software
Still in the SSH window, type the following commands into the command-line and press Enter:

sudo apt-get update
sudo apt-get -y -qq install git
sudo apt-get install python-mpltoolkits.basemap
Enter Y and press Enter when asked Do you want to continue? [Y/n] if it's acceptable to use additional disk space.

Verify that git is now installed:

git --version
You should see the similar output (Don't Copy):

git version 2.20.1
Click Check my progress to verify the objective.
Install software

Task 3. Ingest USGS data
Still in the SSH window, type the following command to download the code from github and press Enter:

git clone https://github.com/GoogleCloudPlatform/training-data-analyst
Note: If you get a git authorization error, the GitHub URL likely has a typo in it. Please copy and paste the above code.
Navigate to the folder corresponding to this lab:

cd training-data-analyst/CPB100/lab2b
Examine the ingest code using less:

less ingest.sh
The less command allows you to view the file (Press the spacebar to scroll down; the letter b to back up a page; the letter q to quit).

Enter q to exit the editor.

The program ingest.sh downloads a dataset of earthquakes in the past 7 days from the US Geological Survey. Notice where the file is downloaded to (disk or Cloud Storage.)

Type the following command to run the ingest code and press Enter:

bash ingest.sh
Click Check my progress to verify the objective.
Ingest USGS data

Task 4. Transform the data
You will use a Python program to transform the raw data into a map of earthquake activity:

The transformation code is explained in detail in this notebook.

Feel free to read the narrative to understand what the transformation code does. The notebook itself was written in Datalab, a Google Cloud product that you will use later in this set of labs.

Still in the SSH window, enter the following command to install the necessary Python packages on the Compute Engine instance:

bash install_missing.sh
Enter the following command to run the transformation code:

python3 transform.py
You will notice a new image file earthquakes.png in your current directory if you enter the following command:

ls -l
dir_listing.png

Click Check my progress to verify the objective.
Transform the data

Task 5. Create a Cloud Storage bucket and Store data
Create a Cloud Storage bucket
Return to the Cloud Platform Console for this step. From the Navigation menu, select Storage > Browser:

storage_nav.png

Click on Create Bucket, then create your bucket with the following characteristics:

For Name your bucket, give a globally unique bucket name (you should use your GCP Project ID), then click Continue.
For Choose where to store your data, select Location type as Multi-region, or improve speed and reduce costs by choosing it as Region (choose the same location as your Compute Engine instance).
Then, click Create.

Take note of your bucket name. You will insert its name whenever the instructions ask for <YOUR-BUCKET>.

Store data
You will now learn how to store the original and transformed data in Cloud Storage.

In the SSH window of the Compute Engine instance, run the following command:

Please replace <YOUR-BUCKET> with the bucket name you created earlier:
gsutil cp earthquakes.* gs://<YOUR-BUCKET>/earthquakes/
This command copies the files to your bucket in Cloud Storage.

Return to the Cloud Platform Console. From the Navigation menu, select Storage > Browser. Click on your bucket, now click on the /earthquakes folder.

You should now see the following three files in the earthquakes folder:

2files.png

Click Check my progress to verify the objective.
Create bucket and Store data

Publish Cloud Storage files to the web
You will now publish the files in your bucket to the web.

To create a publicly accessible URL for the files, click on the three vertical dots drop-down menu on the far right of the earthquakes.htm file.

Select Edit permissions from the drop-down menu.

edit_permissions.png

In the Edit earthquakes.htm permissions page, click the + Add Entry button.

Add permission for all users by entering the following:

Select Public for the Entity.
Select allUsers for the Name.
Select Reader for the Access.
Then click Save.

public-share.png

Repeat the above steps for earthquakes.png to make it publicly accessible.

Click on the name of a file earthquakes.png and notice the Authenticated URL of the published Cloud Storage file and how it relates to your bucket name and content. It should resemble the following:

https://storage.cloud.google.com/YOUR-BUCKET-NAME/earthquakes/earthquakes.png
authenticated_url.png

Click on the earthquakes.png Public URL, a new tab will be opened with the following image loaded:

usgs_map.png

Go ahead and close the SSH window by typing the following command into the command-line and press Enter.

exit
Congratulations!
You have completed this lab and learned how to spin up a compute engine instance, access it remotely, then manually create a pipeline to retrieve, process and publish the data.

Next Steps/Learn More
Here are some follow-up steps:

Check out USGS.gov for complete information. For example:
the latest 20 large earthquakes in the world
geodetic data
hazard assessment data and models, and more.
Sign up for automatic notifications of earthquakes in your area.